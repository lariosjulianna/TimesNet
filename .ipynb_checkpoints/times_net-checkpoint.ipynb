{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch    \n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.fft\n",
    "from layers.Embed import DataEmbedding\n",
    "from layers.Conv_Blocks import Inception_Block_V1   \n",
    "            #convolution block used for convoluting the 2D time data, changeable\n",
    "import math"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Inception_Block_V1(nn.Module):\n",
    "    def __init__(self, in_channels, out_channels, num_kernels=6, init_weight=True): \n",
    "        super(Inception_Block_V1, self).__init__() # initialize parameters and layers\n",
    "        self.in_channels = in_channels # num input channels to block\n",
    "        self.out_channels = out_channels # num output channels from each convolutional kernel\n",
    "        self.num_kernels = num_kernels # num different convolutional kernels to use in inception block\n",
    "        kernels = [] # create list kernels\n",
    "        for i in range(self.num_kernels):\n",
    "            kernels.append(nn.Conv2d(in_channels, out_channels, kernel_size=2 * i + 1, padding=i))\n",
    "        self.kernels = nn.ModuleList(kernels) # kernels list contains num_kernels convolutional layers\n",
    "                                            # each kernel has differnt kernel size, padding = i\n",
    "        if init_weight:\n",
    "            self._initialize_weights()\n",
    "\n",
    "    def _initialize_weights(self): # method\n",
    "        for m in self.modules():\n",
    "            if isinstance(m, nn.Conv2d): # initilizes weights of convolutional layers using kaiming_normal\n",
    "                nn.init.kaiming_normal_(m.weight, mode='fan_out', nonlinearity='relu')\n",
    "                if m.bias is not None:\n",
    "                    nn.init.constant_(m.bias, 0) # initilizes bias to 0, if convolutional layer has bias\n",
    "\n",
    "    # method that performs forward pass through inception block\n",
    "    def forward(self, x): # x is the input tensor to the block\n",
    "        res_list = [] # create res_list list\n",
    "        for i in range(self.num_kernels): # iterates over each convolutional kernel in self.kernels\n",
    "            res_list.append(self.kernels[i](x)) # applies to x and store result in res_list\n",
    "        res = torch.stack(res_list, dim=-1).mean(-1) # stack tesnors along new dimension (dim=-1), takes mean along that dimension\n",
    "        return res #returns tensor, output of the inception block\n",
    "    \n",
    "class TokenEmbedding(nn.Module):\n",
    "    def __init__(self, c_in, d_model): # initializes  class with input channels and output channels or dimensions (parameters)\n",
    "        super(TokenEmbedding, self).__init__()\n",
    "        padding = 1 if torch.__version__ >= '1.5.0' else 2 # sets padding size for convolutional layers\n",
    "        self.tokenConv = nn.Conv1d(in_channels=c_in, out_channels=d_model, # self.tokenCOnv defines a 1D convolutional layer\n",
    "                                   kernel_size=3, padding=padding, padding_mode='circular', bias=False) # circular padding means input is circularly padded to handle edge effects\n",
    "        for m in self.modules():\n",
    "            if isinstance(m, nn.Conv1d):\n",
    "                nn.init.kaiming_normal_(\n",
    "                    m.weight, mode='fan_in', nonlinearity='leaky_relu') # initializes weights of convolutional layers using kaiming init and leaky relu activation\n",
    "\n",
    "    def forward(self, x): # method, x is the input tensor\n",
    "        x = self.tokenConv(x.permute(0, 2, 1)).transpose(1, 2) # permutes dimensions of x to match expected input format of the convolutional layer (x.permute) \n",
    "        # assumes x is a 3D tensor where 2nd dimension is the sequence length\n",
    "        # convolutional layer (self.tokenConv) applied to permuted input tensor\n",
    "        # transposes output tensor, swapping dimensions to return tensr to original shape\n",
    "        return x # returns processed tensor x, represent token embeddings after convolution\n",
    "    \n",
    "class FixedEmbedding(nn.Module):\n",
    "    def __init__(self, c_in, d_model):\n",
    "        super(FixedEmbedding, self).__init__()\n",
    "\n",
    "        w = torch.zeros(c_in, d_model).float() # initilize embedding matrix with zeros\n",
    "        w.require_grad = False # gradients are not computed\n",
    "\n",
    "        # positional encoding\n",
    "        position = torch.arange(0, c_in).float().unsqueeze(1) # [c_in, 1]\n",
    "        div_term = (torch.arange(0, d_model, 2).float()\n",
    "                    * -(math.log(10000.0) / d_model)).exp() # [d_model / 2]\n",
    "\n",
    "        # compute sinusoidal poistional embeddings\n",
    "        w[:, 0::2] = torch.sin(position * div_term) # sinusoidal embeddings for even indices\n",
    "        w[:, 1::2] = torch.cos(position * div_term) # cosinusoidal embeddings for odd indices\n",
    "\n",
    "        # define nn.Embedding layer, set its weight to precomputed positional embeddings\n",
    "        self.emb = nn.Embedding(c_in, d_model)\n",
    "        self.emb.weight = nn.Parameter(w, requires_grad=False) # nn.Parameter to assign w as parameter\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.emb(x).detach() # embedding lookup and detach to avoid gradients during forward pass\n",
    "\n",
    "\n",
    "class TemporalEmbedding(nn.Module):\n",
    "    def __init__(self, d_model, embed_type='fixed', freq='s'):\n",
    "        super(TemporalEmbedding, self).__init__()\n",
    "\n",
    "        minute_size = 4\n",
    "        hour_size = 24\n",
    "        weekday_size = 7\n",
    "        day_size = 32\n",
    "        month_size = 13\n",
    "\n",
    "        Embed = FixedEmbedding if embed_type == 'fixed' else nn.Embedding\n",
    "        if freq == 't':\n",
    "            self.minute_embed = Embed(minute_size, d_model)\n",
    "        self.hour_embed = Embed(hour_size, d_model)\n",
    "        self.weekday_embed = Embed(weekday_size, d_model)\n",
    "        self.day_embed = Embed(day_size, d_model)\n",
    "        self.month_embed = Embed(month_size, d_model)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = x.long()\n",
    "        minute_x = self.minute_embed(x[:, :, 4]) if hasattr(\n",
    "            self, 'minute_embed') else 0.\n",
    "        hour_x = self.hour_embed(x[:, :, 3])\n",
    "        weekday_x = self.weekday_embed(x[:, :, 2])\n",
    "        day_x = self.day_embed(x[:, :, 1])\n",
    "        month_x = self.month_embed(x[:, :, 0])\n",
    "\n",
    "        return hour_x + weekday_x + day_x + month_x + minute_x\n",
    "\n",
    "\n",
    "class TimeFeatureEmbedding(nn.Module):\n",
    "    def __init__(self, d_model, embed_type='timeF', freq='h'):\n",
    "        super(TimeFeatureEmbedding, self).__init__()\n",
    "\n",
    "        freq_map = {'h': 4, 't': 5, 's': 6,\n",
    "                    'm': 1, 'a': 1, 'w': 2, 'd': 3, 'b': 3}\n",
    "        d_inp = freq_map[freq]\n",
    "        self.embed = nn.Linear(d_inp, d_model, bias=False)\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.embed(x)\n",
    "\n",
    "class PositionalEmbedding(nn.Module):\n",
    "    def __init__(self, d_model, max_len=5000):\n",
    "        super(PositionalEmbedding, self).__init__()\n",
    "        # Compute the positional encodings once in log space.\n",
    "        pe = torch.zeros(max_len, d_model).float()\n",
    "        pe.require_grad = False\n",
    "\n",
    "        position = torch.arange(0, max_len).float().unsqueeze(1)\n",
    "        div_term = (torch.arange(0, d_model, 2).float()\n",
    "                    * -(math.log(10000.0) / d_model)).exp()\n",
    "\n",
    "        pe[:, 0::2] = torch.sin(position * div_term)\n",
    "        pe[:, 1::2] = torch.cos(position * div_term)\n",
    "\n",
    "        pe = pe.unsqueeze(0)\n",
    "        self.register_buffer('pe', pe)\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.pe[:, :x.size(1)]\n",
    "    \n",
    "class DataEmbedding(nn.Module):\n",
    "    def __init__(self, c_in, d_model, embed_type='fixed', freq='h', dropout=0.1):\n",
    "        super(DataEmbedding, self).__init__()\n",
    "\n",
    "        self.value_embedding = TokenEmbedding(c_in=c_in, d_model=d_model)\n",
    "        self.position_embedding = PositionalEmbedding(d_model=d_model)\n",
    "        self.temporal_embedding = TemporalEmbedding(d_model=d_model, embed_type=embed_type,\n",
    "                                                    freq=freq) if embed_type != 'timeF' else TimeFeatureEmbedding(\n",
    "            d_model=d_model, embed_type=embed_type, freq=freq)\n",
    "        self.dropout = nn.Dropout(p=dropout)\n",
    "\n",
    "    def forward(self, x, x_mark):\n",
    "        if x_mark is None:\n",
    "            x = self.value_embedding(x) + self.position_embedding(x)\n",
    "        else:\n",
    "            x = self.value_embedding(\n",
    "                x) + self.temporal_embedding(x_mark) + self.position_embedding(x)\n",
    "        return self.dropout(x)\n",
    "\n",
    "def FFT_for_Period(x, k=2):\n",
    "    # [B, T, C]\n",
    "    xf = torch.fft.rfft(x, dim=1)\n",
    "    # find period by amplitudes\n",
    "    frequency_list = abs(xf).mean(0).mean(-1)\n",
    "    frequency_list[0] = 0\n",
    "    _, top_list = torch.topk(frequency_list, k)\n",
    "    top_list = top_list.detach().cpu().numpy()\n",
    "    period = x.shape[1] // top_list\n",
    "    return period, abs(xf).mean(-1)[:, top_list]\n",
    "\n",
    "\n",
    "class TimesBlock(nn.Module):\n",
    "    def __init__(self, seq_len, pred_len, top_k, d_model, d_ff=32, num_kernels=6):\n",
    "        \"\"\"\n",
    "        seq_len: int, the length of the input sequence\n",
    "        pred_len: int, the length of the prediction sequence\n",
    "        top_k: int denotes how many top frequencies are taken into consideration\n",
    "        d_model is the dimension of embedding\n",
    "        \"\"\"\n",
    "        super(TimesBlock, self).__init__()\n",
    "        self.seq_len = seq_len\n",
    "        self.pred_len = pred_len\n",
    "        self.k = top_k\n",
    "        # parameter-efficient design\n",
    "        self.conv = nn.Sequential(\n",
    "            Inception_Block_V1(d_model, d_ff,\n",
    "                               num_kernels=num_kernels),\n",
    "            nn.GELU(),\n",
    "            Inception_Block_V1(d_ff, d_model,\n",
    "                               num_kernels=num_kernels)\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        B, T, N = x.size()\n",
    "        period_list, period_weight = FFT_for_Period(x, self.k)\n",
    "\n",
    "        res = []\n",
    "        for i in range(self.k):\n",
    "            period = period_list[i]\n",
    "            # padding\n",
    "            if (self.seq_len + self.pred_len) % period != 0:\n",
    "                length = (\n",
    "                                 ((self.seq_len + self.pred_len) // period) + 1) * period\n",
    "                padding = torch.zeros([x.shape[0], (length - (self.seq_len + self.pred_len)), x.shape[2]]).to(x.device)\n",
    "                out = torch.cat([x, padding], dim=1)\n",
    "            else:\n",
    "                length = (self.seq_len + self.pred_len)\n",
    "                out = x\n",
    "            # reshape\n",
    "            out = out.reshape(B, length // period, period,\n",
    "                              N).permute(0, 3, 1, 2).contiguous()\n",
    "            # 2D conv: from 1d Variation to 2d Variation\n",
    "            out = self.conv(out)\n",
    "            # reshape back\n",
    "            out = out.permute(0, 2, 3, 1).reshape(B, -1, N)\n",
    "            res.append(out[:, :(self.seq_len + self.pred_len), :])\n",
    "        res = torch.stack(res, dim=-1)\n",
    "        # adaptive aggregation\n",
    "        period_weight = F.softmax(period_weight, dim=1)\n",
    "        period_weight = period_weight.unsqueeze(\n",
    "            1).unsqueeze(1).repeat(1, T, N, 1)\n",
    "        res = torch.sum(res * period_weight, -1)\n",
    "        # residual connection\n",
    "        res = res + x\n",
    "        return res\n",
    "\n",
    "\n",
    "class Model(nn.Module):\n",
    "    \"\"\"\n",
    "    Paper link: https://openreview.net/pdf?id=ju_Uqw384Oq\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, seq_len, label_len, pred_len, num_encoder_layers=2, top_k=5, d_model=16, enc_in=3, embed=\"timeF\", freq=\"s\", dropout=0, c_out=3):\n",
    "        \"\"\"\n",
    "        enc_in is the encoder input size, the number of features for a piece of data\n",
    "        c_out is the output size, the number of features for a piece of data\n",
    "        \"\"\"\n",
    "        super(Model, self).__init__()\n",
    "        self.seq_len = seq_len\n",
    "        self.label_len = label_len\n",
    "        self.pred_len = pred_len\n",
    "        self.model = nn.ModuleList([TimesBlock(seq_len, pred_len, top_k, d_model, d_ff=32, num_kernels=6)\n",
    "                                    for _ in range(num_encoder_layers)])\n",
    "        self.enc_embedding = DataEmbedding(enc_in, d_model, embed, freq, dropout)\n",
    "        self.layer = num_encoder_layers\n",
    "        self.layer_norm = nn.LayerNorm(d_model)\n",
    "        self.predict_linear = nn.Linear(\n",
    "            self.seq_len, self.pred_len + self.seq_len)\n",
    "        self.projection = nn.Linear(\n",
    "            d_model, c_out, bias=True)\n",
    "        \n",
    "    def forecast(self, x_enc, x_mark_enc):\n",
    "        # Normalization from Non-stationary Transformer\n",
    "        means = x_enc.mean(1, keepdim=True).detach()\n",
    "        x_enc = x_enc - means\n",
    "        stdev = torch.sqrt(\n",
    "            torch.var(x_enc, dim=1, keepdim=True, unbiased=False) + 1e-5)\n",
    "        x_enc /= stdev\n",
    "\n",
    "        # embedding\n",
    "        enc_out = self.enc_embedding(x_enc, x_mark_enc)  # [B,T,C]\n",
    "        enc_out = self.predict_linear(enc_out.permute(0, 2, 1)).permute(\n",
    "            0, 2, 1)  # align temporal dimension\n",
    "        # TimesNet\n",
    "        for i in range(self.layer):\n",
    "            enc_out = self.layer_norm(self.model[i](enc_out))\n",
    "        # porject back\n",
    "        dec_out = self.projection(enc_out)\n",
    "\n",
    "        # De-Normalization from Non-stationary Transformer\n",
    "        dec_out = dec_out * \\\n",
    "                  (stdev[:, 0, :].unsqueeze(1).repeat(\n",
    "                      1, self.pred_len + self.seq_len, 1))\n",
    "        dec_out = dec_out + \\\n",
    "                  (means[:, 0, :].unsqueeze(1).repeat(\n",
    "                      1, self.pred_len + self.seq_len, 1))\n",
    "        return dec_out\n",
    "\n",
    "\n",
    "    def forward(self, x_enc, x_mark_enc):\n",
    "        dec_out = self.forecast(x_enc, x_mark_enc)\n",
    "        return dec_out[:, -self.pred_len:, :]  # [B, L, D]\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'matplotlib'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[13], line 4\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mdata_provider\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mdata_factory\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m data_provider\n\u001b[1;32m      3\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mdata_provider\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mm4\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m M4Meta\n\u001b[0;32m----> 4\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mexp\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mexp_basic\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m Exp_Basic\n\u001b[1;32m      5\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mutils\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mtools\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m EarlyStopping, adjust_learning_rate, visual\n\u001b[1;32m      6\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mutils\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mlosses\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m mape_loss, mase_loss, smape_loss\n",
      "File \u001b[0;32m~/timesnet/uc/timesnet/exp/exp_basic.py:3\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mos\u001b[39;00m\n\u001b[1;32m      2\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mtorch\u001b[39;00m\n\u001b[0;32m----> 3\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mmodels\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m Autoformer, Transformer, TimesNet, Nonstationary_Transformer, DLinear, FEDformer, \\\n\u001b[1;32m      4\u001b[0m     Informer, LightTS, Reformer, ETSformer, Pyraformer, PatchTST, MICN, Crossformer, FiLM, iTransformer, \\\n\u001b[1;32m      5\u001b[0m     Koopa, TiDE, FreTS, TimeMixer, TSMixer, SegRNN, MambaSimple, Mamba, TemporalFusionTransformer\n\u001b[1;32m      8\u001b[0m \u001b[38;5;28;01mclass\u001b[39;00m \u001b[38;5;21;01mExp_Basic\u001b[39;00m(\u001b[38;5;28mobject\u001b[39m):\n\u001b[1;32m      9\u001b[0m     \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__init__\u001b[39m(\u001b[38;5;28mself\u001b[39m, args):\n",
      "File \u001b[0;32m~/timesnet/uc/timesnet/models/Autoformer.py:5\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mtorch\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mnn\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mfunctional\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mF\u001b[39;00m\n\u001b[1;32m      4\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mlayers\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mEmbed\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m DataEmbedding, DataEmbedding_wo_pos\n\u001b[0;32m----> 5\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mlayers\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mAutoCorrelation\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m AutoCorrelation, AutoCorrelationLayer\n\u001b[1;32m      6\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mlayers\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mAutoformer_EncDec\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m Encoder, Decoder, EncoderLayer, DecoderLayer, my_Layernorm, series_decomp\n\u001b[1;32m      7\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mmath\u001b[39;00m\n",
      "File \u001b[0;32m~/timesnet/uc/timesnet/layers/AutoCorrelation.py:4\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mtorch\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mnn\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mnn\u001b[39;00m\n\u001b[1;32m      3\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mtorch\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mnn\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mfunctional\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mF\u001b[39;00m\n\u001b[0;32m----> 4\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mmatplotlib\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpyplot\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mplt\u001b[39;00m\n\u001b[1;32m      5\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mnumpy\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mnp\u001b[39;00m\n\u001b[1;32m      6\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mmath\u001b[39;00m\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'matplotlib'"
     ]
    }
   ],
   "source": [
    "# short term forecasting\n",
    "from data_provider.data_factory import data_provider\n",
    "from data_provider.m4 import M4Meta\n",
    "from exp.exp_basic import Exp_Basic\n",
    "from utils.tools import EarlyStopping, adjust_learning_rate, visual\n",
    "from utils.losses import mape_loss, mase_loss, smape_loss\n",
    "from utils.m4_summary import M4Summary\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch import optim\n",
    "import os\n",
    "import time\n",
    "import warnings\n",
    "import numpy as np\n",
    "import pandas\n",
    "\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "\n",
    "class Exp_Short_Term_Forecast(Exp_Basic):\n",
    "    def __init__(self, args):\n",
    "        super(Exp_Short_Term_Forecast, self).__init__(args)\n",
    "\n",
    "    def _build_model(self):\n",
    "        if self.args.data == 'm4':\n",
    "            self.args.pred_len = M4Meta.horizons_map[self.args.seasonal_patterns]  # Up to M4 config\n",
    "            self.args.seq_len = 2 * self.args.pred_len  # input_len = 2*pred_len\n",
    "            self.args.label_len = self.args.pred_len\n",
    "            self.args.frequency_map = M4Meta.frequency_map[self.args.seasonal_patterns]\n",
    "        model = self.model_dict[self.args.model].Model(self.args).float()\n",
    "\n",
    "        if self.args.use_multi_gpu and self.args.use_gpu:\n",
    "            model = nn.DataParallel(model, device_ids=self.args.device_ids)\n",
    "        return model\n",
    "\n",
    "    def _get_data(self, flag):\n",
    "        data_set, data_loader = data_provider(self.args, flag)\n",
    "        return data_set, data_loader\n",
    "\n",
    "    def _select_optimizer(self):\n",
    "        model_optim = optim.Adam(self.model.parameters(), lr=self.args.learning_rate)\n",
    "        return model_optim\n",
    "\n",
    "    def _select_criterion(self, loss_name='MSE'):\n",
    "        if loss_name == 'MSE':\n",
    "            return nn.MSELoss()\n",
    "        elif loss_name == 'MAPE':\n",
    "            return mape_loss()\n",
    "        elif loss_name == 'MASE':\n",
    "            return mase_loss()\n",
    "        elif loss_name == 'SMAPE':\n",
    "            return smape_loss()\n",
    "\n",
    "    def train(self, setting):\n",
    "        train_data, train_loader = self._get_data(flag='train')\n",
    "        vali_data, vali_loader = self._get_data(flag='val')\n",
    "\n",
    "        path = os.path.join(self.args.checkpoints, setting)\n",
    "        if not os.path.exists(path):\n",
    "            os.makedirs(path)\n",
    "\n",
    "        time_now = time.time()\n",
    "\n",
    "        train_steps = len(train_loader)\n",
    "        early_stopping = EarlyStopping(patience=self.args.patience, verbose=True)\n",
    "\n",
    "        model_optim = self._select_optimizer()\n",
    "        criterion = self._select_criterion(self.args.loss)\n",
    "        mse = nn.MSELoss()\n",
    "\n",
    "        for epoch in range(self.args.train_epochs):\n",
    "            iter_count = 0\n",
    "            train_loss = []\n",
    "\n",
    "            self.model.train()\n",
    "            epoch_time = time.time()\n",
    "            for i, (batch_x, batch_y, batch_x_mark, batch_y_mark) in enumerate(train_loader):\n",
    "                iter_count += 1\n",
    "                model_optim.zero_grad()\n",
    "                batch_x = batch_x.float().to(self.device)\n",
    "\n",
    "                batch_y = batch_y.float().to(self.device)\n",
    "                batch_y_mark = batch_y_mark.float().to(self.device)\n",
    "\n",
    "                # decoder input\n",
    "                dec_inp = torch.zeros_like(batch_y[:, -self.args.pred_len:, :]).float()\n",
    "                dec_inp = torch.cat([batch_y[:, :self.args.label_len, :], dec_inp], dim=1).float().to(self.device)\n",
    "\n",
    "                outputs = self.model(batch_x, None, dec_inp, None)\n",
    "\n",
    "                f_dim = -1 if self.args.features == 'MS' else 0\n",
    "                outputs = outputs[:, -self.args.pred_len:, f_dim:]\n",
    "                batch_y = batch_y[:, -self.args.pred_len:, f_dim:].to(self.device)\n",
    "\n",
    "                batch_y_mark = batch_y_mark[:, -self.args.pred_len:, f_dim:].to(self.device)\n",
    "                loss_value = criterion(batch_x, self.args.frequency_map, outputs, batch_y, batch_y_mark)\n",
    "                loss_sharpness = mse((outputs[:, 1:, :] - outputs[:, :-1, :]), (batch_y[:, 1:, :] - batch_y[:, :-1, :]))\n",
    "                loss = loss_value  # + loss_sharpness * 1e-5\n",
    "                train_loss.append(loss.item())\n",
    "\n",
    "                if (i + 1) % 100 == 0:\n",
    "                    print(\"\\titers: {0}, epoch: {1} | loss: {2:.7f}\".format(i + 1, epoch + 1, loss.item()))\n",
    "                    speed = (time.time() - time_now) / iter_count\n",
    "                    left_time = speed * ((self.args.train_epochs - epoch) * train_steps - i)\n",
    "                    print('\\tspeed: {:.4f}s/iter; left time: {:.4f}s'.format(speed, left_time))\n",
    "                    iter_count = 0\n",
    "                    time_now = time.time()\n",
    "\n",
    "                loss.backward()\n",
    "                model_optim.step()\n",
    "\n",
    "            print(\"Epoch: {} cost time: {}\".format(epoch + 1, time.time() - epoch_time))\n",
    "            train_loss = np.average(train_loss)\n",
    "            vali_loss = self.vali(train_loader, vali_loader, criterion)\n",
    "            test_loss = vali_loss\n",
    "            print(\"Epoch: {0}, Steps: {1} | Train Loss: {2:.7f} Vali Loss: {3:.7f} Test Loss: {4:.7f}\".format(\n",
    "                epoch + 1, train_steps, train_loss, vali_loss, test_loss))\n",
    "            early_stopping(vali_loss, self.model, path)\n",
    "            if early_stopping.early_stop:\n",
    "                print(\"Early stopping\")\n",
    "                break\n",
    "\n",
    "            adjust_learning_rate(model_optim, epoch + 1, self.args)\n",
    "\n",
    "        best_model_path = path + '/' + 'checkpoint.pth'\n",
    "        self.model.load_state_dict(torch.load(best_model_path))\n",
    "\n",
    "        return self.model\n",
    "\n",
    "    def vali(self, train_loader, vali_loader, criterion):\n",
    "        x, _ = train_loader.dataset.last_insample_window()\n",
    "        y = vali_loader.dataset.timeseries\n",
    "        x = torch.tensor(x, dtype=torch.float32).to(self.device)\n",
    "        x = x.unsqueeze(-1)\n",
    "\n",
    "        self.model.eval()\n",
    "        with torch.no_grad():\n",
    "            # decoder input\n",
    "            B, _, C = x.shape\n",
    "            dec_inp = torch.zeros((B, self.args.pred_len, C)).float().to(self.device)\n",
    "            dec_inp = torch.cat([x[:, -self.args.label_len:, :], dec_inp], dim=1).float()\n",
    "            # encoder - decoder\n",
    "            outputs = torch.zeros((B, self.args.pred_len, C)).float()  # .to(self.device)\n",
    "            id_list = np.arange(0, B, 500)  # validation set size\n",
    "            id_list = np.append(id_list, B)\n",
    "            for i in range(len(id_list) - 1):\n",
    "                outputs[id_list[i]:id_list[i + 1], :, :] = self.model(x[id_list[i]:id_list[i + 1]], None,\n",
    "                                                                      dec_inp[id_list[i]:id_list[i + 1]],\n",
    "                                                                      None).detach().cpu()\n",
    "            f_dim = -1 if self.args.features == 'MS' else 0\n",
    "            outputs = outputs[:, -self.args.pred_len:, f_dim:]\n",
    "            pred = outputs\n",
    "            true = torch.from_numpy(np.array(y))\n",
    "            batch_y_mark = torch.ones(true.shape)\n",
    "\n",
    "            loss = criterion(x.detach().cpu()[:, :, 0], self.args.frequency_map, pred[:, :, 0], true, batch_y_mark)\n",
    "\n",
    "        self.model.train()\n",
    "        return loss\n",
    "\n",
    "    def test(self, setting, test=0):\n",
    "        _, train_loader = self._get_data(flag='train')\n",
    "        _, test_loader = self._get_data(flag='test')\n",
    "        x, _ = train_loader.dataset.last_insample_window()\n",
    "        y = test_loader.dataset.timeseries\n",
    "        x = torch.tensor(x, dtype=torch.float32).to(self.device)\n",
    "        x = x.unsqueeze(-1)\n",
    "\n",
    "        if test:\n",
    "            print('loading model')\n",
    "            self.model.load_state_dict(torch.load(os.path.join('./checkpoints/' + setting, 'checkpoint.pth')))\n",
    "\n",
    "        folder_path = './test_results/' + setting + '/'\n",
    "        if not os.path.exists(folder_path):\n",
    "            os.makedirs(folder_path)\n",
    "\n",
    "        self.model.eval()\n",
    "        with torch.no_grad():\n",
    "            B, _, C = x.shape\n",
    "            dec_inp = torch.zeros((B, self.args.pred_len, C)).float().to(self.device)\n",
    "            dec_inp = torch.cat([x[:, -self.args.label_len:, :], dec_inp], dim=1).float()\n",
    "            # encoder - decoder\n",
    "            outputs = torch.zeros((B, self.args.pred_len, C)).float().to(self.device)\n",
    "            id_list = np.arange(0, B, 1)\n",
    "            id_list = np.append(id_list, B)\n",
    "            for i in range(len(id_list) - 1):\n",
    "                outputs[id_list[i]:id_list[i + 1], :, :] = self.model(x[id_list[i]:id_list[i + 1]], None,\n",
    "                                                                      dec_inp[id_list[i]:id_list[i + 1]], None)\n",
    "\n",
    "                if id_list[i] % 1000 == 0:\n",
    "                    print(id_list[i])\n",
    "\n",
    "            f_dim = -1 if self.args.features == 'MS' else 0\n",
    "            outputs = outputs[:, -self.args.pred_len:, f_dim:]\n",
    "            outputs = outputs.detach().cpu().numpy()\n",
    "\n",
    "            preds = outputs\n",
    "            trues = y\n",
    "            x = x.detach().cpu().numpy()\n",
    "\n",
    "            for i in range(0, preds.shape[0], preds.shape[0] // 10):\n",
    "                gt = np.concatenate((x[i, :, 0], trues[i]), axis=0)\n",
    "                pd = np.concatenate((x[i, :, 0], preds[i, :, 0]), axis=0)\n",
    "                visual(gt, pd, os.path.join(folder_path, str(i) + '.pdf'))\n",
    "\n",
    "        print('test shape:', preds.shape)\n",
    "\n",
    "        # result save\n",
    "        folder_path = './m4_results/' + self.args.model + '/'\n",
    "        if not os.path.exists(folder_path):\n",
    "            os.makedirs(folder_path)\n",
    "\n",
    "        forecasts_df = pandas.DataFrame(preds[:, :, 0], columns=[f'V{i + 1}' for i in range(self.args.pred_len)])\n",
    "        forecasts_df.index = test_loader.dataset.ids[:preds.shape[0]]\n",
    "        forecasts_df.index.name = 'id'\n",
    "        forecasts_df.set_index(forecasts_df.columns[0], inplace=True)\n",
    "        forecasts_df.to_csv(folder_path + self.args.seasonal_patterns + '_forecast.csv')\n",
    "\n",
    "        print(self.args.model)\n",
    "        file_path = './m4_results/' + self.args.model + '/'\n",
    "        if 'Weekly_forecast.csv' in os.listdir(file_path) \\\n",
    "                and 'Monthly_forecast.csv' in os.listdir(file_path) \\\n",
    "                and 'Yearly_forecast.csv' in os.listdir(file_path) \\\n",
    "                and 'Daily_forecast.csv' in os.listdir(file_path) \\\n",
    "                and 'Hourly_forecast.csv' in os.listdir(file_path) \\\n",
    "                and 'Quarterly_forecast.csv' in os.listdir(file_path):\n",
    "            m4_summary = M4Summary(file_path, self.args.root_path)\n",
    "            # m4_forecast.set_index(m4_winner_forecast.columns[0], inplace=True)\n",
    "            smape_results, owa_results, mape, mase = m4_summary.evaluate()\n",
    "            print('smape:', smape_results)\n",
    "            print('mape:', mape)\n",
    "            print('mase:', mase)\n",
    "            print('owa:', owa_results)\n",
    "        else:\n",
    "            print('After all 6 tasks are finished, you can calculate the averaged index')\n",
    "        return"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "timesnet-env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
