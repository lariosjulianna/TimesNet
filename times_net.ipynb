{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: einops==0.4.0 in /csse/users/jla256/miniconda3/envs/timesnet-env2/lib/python3.8/site-packages (from -r requirements.txt (line 1)) (0.4.0)\n",
      "Requirement already satisfied: matplotlib==3.7.0 in /csse/users/jla256/miniconda3/envs/timesnet-env2/lib/python3.8/site-packages (from -r requirements.txt (line 2)) (3.7.0)\n",
      "Requirement already satisfied: numpy==1.23.5 in /csse/users/jla256/miniconda3/envs/timesnet-env2/lib/python3.8/site-packages (from -r requirements.txt (line 3)) (1.23.5)\n",
      "Requirement already satisfied: pandas==1.5.3 in /csse/users/jla256/miniconda3/envs/timesnet-env2/lib/python3.8/site-packages (from -r requirements.txt (line 4)) (1.5.3)\n",
      "Requirement already satisfied: patool==1.12 in /csse/users/jla256/miniconda3/envs/timesnet-env2/lib/python3.8/site-packages (from -r requirements.txt (line 5)) (1.12)\n",
      "Requirement already satisfied: reformer-pytorch==1.4.4 in /csse/users/jla256/miniconda3/envs/timesnet-env2/lib/python3.8/site-packages (from -r requirements.txt (line 6)) (1.4.4)\n",
      "Requirement already satisfied: scikit-learn==1.2.2 in /csse/users/jla256/miniconda3/envs/timesnet-env2/lib/python3.8/site-packages (from -r requirements.txt (line 7)) (1.2.2)\n",
      "Requirement already satisfied: scipy==1.10.1 in /csse/users/jla256/miniconda3/envs/timesnet-env2/lib/python3.8/site-packages (from -r requirements.txt (line 8)) (1.10.1)\n",
      "Requirement already satisfied: sktime==0.16.1 in /csse/users/jla256/miniconda3/envs/timesnet-env2/lib/python3.8/site-packages (from -r requirements.txt (line 9)) (0.16.1)\n",
      "Requirement already satisfied: sympy==1.11.1 in /csse/users/jla256/miniconda3/envs/timesnet-env2/lib/python3.8/site-packages (from -r requirements.txt (line 10)) (1.11.1)\n",
      "Requirement already satisfied: torch==1.7.1 in /csse/users/jla256/miniconda3/envs/timesnet-env2/lib/python3.8/site-packages (from -r requirements.txt (line 11)) (1.7.1)\n",
      "Requirement already satisfied: tqdm==4.64.1 in /csse/users/jla256/miniconda3/envs/timesnet-env2/lib/python3.8/site-packages (from -r requirements.txt (line 12)) (4.64.1)\n",
      "Requirement already satisfied: contourpy>=1.0.1 in /csse/users/jla256/miniconda3/envs/timesnet-env2/lib/python3.8/site-packages (from matplotlib==3.7.0->-r requirements.txt (line 2)) (1.1.1)\n",
      "Requirement already satisfied: cycler>=0.10 in /csse/users/jla256/miniconda3/envs/timesnet-env2/lib/python3.8/site-packages (from matplotlib==3.7.0->-r requirements.txt (line 2)) (0.12.1)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in /csse/users/jla256/miniconda3/envs/timesnet-env2/lib/python3.8/site-packages (from matplotlib==3.7.0->-r requirements.txt (line 2)) (4.53.0)\n",
      "Requirement already satisfied: kiwisolver>=1.0.1 in /csse/users/jla256/miniconda3/envs/timesnet-env2/lib/python3.8/site-packages (from matplotlib==3.7.0->-r requirements.txt (line 2)) (1.4.5)\n",
      "Requirement already satisfied: packaging>=20.0 in /csse/users/jla256/miniconda3/envs/timesnet-env2/lib/python3.8/site-packages (from matplotlib==3.7.0->-r requirements.txt (line 2)) (24.1)\n",
      "Requirement already satisfied: pillow>=6.2.0 in /csse/users/jla256/miniconda3/envs/timesnet-env2/lib/python3.8/site-packages (from matplotlib==3.7.0->-r requirements.txt (line 2)) (10.3.0)\n",
      "Requirement already satisfied: pyparsing>=2.3.1 in /csse/users/jla256/miniconda3/envs/timesnet-env2/lib/python3.8/site-packages (from matplotlib==3.7.0->-r requirements.txt (line 2)) (3.1.2)\n",
      "Requirement already satisfied: python-dateutil>=2.7 in /csse/users/jla256/miniconda3/envs/timesnet-env2/lib/python3.8/site-packages (from matplotlib==3.7.0->-r requirements.txt (line 2)) (2.9.0)\n",
      "Requirement already satisfied: importlib-resources>=3.2.0 in /csse/users/jla256/miniconda3/envs/timesnet-env2/lib/python3.8/site-packages (from matplotlib==3.7.0->-r requirements.txt (line 2)) (6.4.0)\n",
      "Requirement already satisfied: pytz>=2020.1 in /csse/users/jla256/miniconda3/envs/timesnet-env2/lib/python3.8/site-packages (from pandas==1.5.3->-r requirements.txt (line 4)) (2024.1)\n",
      "Requirement already satisfied: axial-positional-embedding>=0.1.0 in /csse/users/jla256/miniconda3/envs/timesnet-env2/lib/python3.8/site-packages (from reformer-pytorch==1.4.4->-r requirements.txt (line 6)) (0.2.1)\n",
      "Requirement already satisfied: local-attention in /csse/users/jla256/miniconda3/envs/timesnet-env2/lib/python3.8/site-packages (from reformer-pytorch==1.4.4->-r requirements.txt (line 6)) (1.4.4)\n",
      "Requirement already satisfied: product-key-memory in /csse/users/jla256/miniconda3/envs/timesnet-env2/lib/python3.8/site-packages (from reformer-pytorch==1.4.4->-r requirements.txt (line 6)) (0.1.10)\n",
      "Requirement already satisfied: joblib>=1.1.1 in /csse/users/jla256/miniconda3/envs/timesnet-env2/lib/python3.8/site-packages (from scikit-learn==1.2.2->-r requirements.txt (line 7)) (1.4.2)\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in /csse/users/jla256/miniconda3/envs/timesnet-env2/lib/python3.8/site-packages (from scikit-learn==1.2.2->-r requirements.txt (line 7)) (3.5.0)\n",
      "Requirement already satisfied: deprecated>=1.2.13 in /csse/users/jla256/miniconda3/envs/timesnet-env2/lib/python3.8/site-packages (from sktime==0.16.1->-r requirements.txt (line 9)) (1.2.14)\n",
      "Requirement already satisfied: numba>=0.53 in /csse/users/jla256/miniconda3/envs/timesnet-env2/lib/python3.8/site-packages (from sktime==0.16.1->-r requirements.txt (line 9)) (0.58.1)\n",
      "Requirement already satisfied: mpmath>=0.19 in /csse/users/jla256/miniconda3/envs/timesnet-env2/lib/python3.8/site-packages (from sympy==1.11.1->-r requirements.txt (line 10)) (1.3.0)\n",
      "Requirement already satisfied: typing-extensions in /csse/users/jla256/miniconda3/envs/timesnet-env2/lib/python3.8/site-packages (from torch==1.7.1->-r requirements.txt (line 11)) (4.12.2)\n",
      "Requirement already satisfied: wrapt<2,>=1.10 in /csse/users/jla256/miniconda3/envs/timesnet-env2/lib/python3.8/site-packages (from deprecated>=1.2.13->sktime==0.16.1->-r requirements.txt (line 9)) (1.16.0)\n",
      "Requirement already satisfied: zipp>=3.1.0 in /csse/users/jla256/miniconda3/envs/timesnet-env2/lib/python3.8/site-packages (from importlib-resources>=3.2.0->matplotlib==3.7.0->-r requirements.txt (line 2)) (3.19.2)\n",
      "Requirement already satisfied: llvmlite<0.42,>=0.41.0dev0 in /csse/users/jla256/miniconda3/envs/timesnet-env2/lib/python3.8/site-packages (from numba>=0.53->sktime==0.16.1->-r requirements.txt (line 9)) (0.41.1)\n",
      "Requirement already satisfied: importlib-metadata in /csse/users/jla256/miniconda3/envs/timesnet-env2/lib/python3.8/site-packages (from numba>=0.53->sktime==0.16.1->-r requirements.txt (line 9)) (7.1.0)\n",
      "Requirement already satisfied: six>=1.5 in /csse/users/jla256/miniconda3/envs/timesnet-env2/lib/python3.8/site-packages (from python-dateutil>=2.7->matplotlib==3.7.0->-r requirements.txt (line 2)) (1.16.0)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install -r requirements.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/csse/users/jla256/miniconda3/envs/timesnet-env2/lib/python3.8/site-packages/tqdm/auto.py:22: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import torch    \n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.fft\n",
    "from layers.Embed import DataEmbedding\n",
    "from layers.Conv_Blocks import Inception_Block_V1   \n",
    "            #convolution block used for convoluting the 2D time data, changeable\n",
    "import math"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Inception_Block_V1(nn.Module):\n",
    "    def __init__(self, in_channels, out_channels, num_kernels=6, init_weight=True): \n",
    "        super(Inception_Block_V1, self).__init__() # initialize parameters and layers\n",
    "        self.in_channels = in_channels # num input channels to block\n",
    "        self.out_channels = out_channels # num output channels from each convolutional kernel\n",
    "        self.num_kernels = num_kernels # num different convolutional kernels to use in inception block\n",
    "        kernels = [] # create list kernels\n",
    "        for i in range(self.num_kernels):\n",
    "            kernels.append(nn.Conv2d(in_channels, out_channels, kernel_size=2 * i + 1, padding=i))\n",
    "        self.kernels = nn.ModuleList(kernels) # kernels list contains num_kernels convolutional layers\n",
    "                                            # each kernel has differnt kernel size, padding = i\n",
    "        if init_weight:\n",
    "            self._initialize_weights()\n",
    "\n",
    "    def _initialize_weights(self): # method\n",
    "        for m in self.modules():\n",
    "            if isinstance(m, nn.Conv2d): # initilizes weights of convolutional layers using kaiming_normal\n",
    "                nn.init.kaiming_normal_(m.weight, mode='fan_out', nonlinearity='relu')\n",
    "                if m.bias is not None:\n",
    "                    nn.init.constant_(m.bias, 0) # initilizes bias to 0, if convolutional layer has bias\n",
    "\n",
    "    # method that performs forward pass through inception block\n",
    "    def forward(self, x): # x is the input tensor to the block\n",
    "        res_list = [] # create res_list list\n",
    "        for i in range(self.num_kernels): # iterates over each convolutional kernel in self.kernels\n",
    "            res_list.append(self.kernels[i](x)) # applies to x and store result in res_list\n",
    "        res = torch.stack(res_list, dim=-1).mean(-1) # stack tesnors along new dimension (dim=-1), takes mean along that dimension\n",
    "        return res #returns tensor, output of the inception block\n",
    "    \n",
    "class TokenEmbedding(nn.Module):\n",
    "    def __init__(self, c_in, d_model): # initializes  class with input channels and output channels or dimensions (parameters)\n",
    "        super(TokenEmbedding, self).__init__()\n",
    "        padding = 1 if torch.__version__ >= '1.5.0' else 2 # sets padding size for convolutional layers\n",
    "        self.tokenConv = nn.Conv1d(in_channels=c_in, out_channels=d_model, # self.tokenCOnv defines a 1D convolutional layer\n",
    "                                   kernel_size=3, padding=padding, padding_mode='circular', bias=False) # circular padding means input is circularly padded to handle edge effects\n",
    "        for m in self.modules():\n",
    "            if isinstance(m, nn.Conv1d):\n",
    "                nn.init.kaiming_normal_(\n",
    "                    m.weight, mode='fan_in', nonlinearity='leaky_relu') # initializes weights of convolutional layers using kaiming init and leaky relu activation\n",
    "\n",
    "    def forward(self, x): # method, x is the input tensor\n",
    "        x = self.tokenConv(x.permute(0, 2, 1)).transpose(1, 2) # permutes dimensions of x to match expected input format of the convolutional layer (x.permute) \n",
    "        # assumes x is a 3D tensor where 2nd dimension is the sequence length\n",
    "        # convolutional layer (self.tokenConv) applied to permuted input tensor\n",
    "        # transposes output tensor, swapping dimensions to return tensr to original shape\n",
    "        return x # returns processed tensor x, represent token embeddings after convolution\n",
    "    \n",
    "class FixedEmbedding(nn.Module):\n",
    "    def __init__(self, c_in, d_model):\n",
    "        super(FixedEmbedding, self).__init__()\n",
    "\n",
    "        w = torch.zeros(c_in, d_model).float() # initilize embedding matrix with zeros\n",
    "        w.require_grad = False # gradients are not computed\n",
    "\n",
    "        # positional encoding\n",
    "        position = torch.arange(0, c_in).float().unsqueeze(1) # [c_in, 1]\n",
    "        div_term = (torch.arange(0, d_model, 2).float()\n",
    "                    * -(math.log(10000.0) / d_model)).exp() # [d_model / 2]\n",
    "\n",
    "        # compute sinusoidal poistional embeddings\n",
    "        w[:, 0::2] = torch.sin(position * div_term) # sinusoidal embeddings for even indices\n",
    "        w[:, 1::2] = torch.cos(position * div_term) # cosinusoidal embeddings for odd indices\n",
    "\n",
    "        # define nn.Embedding layer, set its weight to precomputed positional embeddings\n",
    "        self.emb = nn.Embedding(c_in, d_model)\n",
    "        self.emb.weight = nn.Parameter(w, requires_grad=False) # nn.Parameter to assign w as parameter\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.emb(x).detach() # embedding lookup and detach to avoid gradients during forward pass\n",
    "\n",
    "\n",
    "class TemporalEmbedding(nn.Module):\n",
    "    def __init__(self, d_model, embed_type='fixed', freq='s'):\n",
    "        super(TemporalEmbedding, self).__init__()\n",
    "\n",
    "        minute_size = 4\n",
    "        hour_size = 24\n",
    "        weekday_size = 7\n",
    "        day_size = 32\n",
    "        month_size = 13\n",
    "\n",
    "        Embed = FixedEmbedding if embed_type == 'fixed' else nn.Embedding\n",
    "        if freq == 't':\n",
    "            self.minute_embed = Embed(minute_size, d_model)\n",
    "        self.hour_embed = Embed(hour_size, d_model)\n",
    "        self.weekday_embed = Embed(weekday_size, d_model)\n",
    "        self.day_embed = Embed(day_size, d_model)\n",
    "        self.month_embed = Embed(month_size, d_model)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = x.long()\n",
    "        minute_x = self.minute_embed(x[:, :, 4]) if hasattr(\n",
    "            self, 'minute_embed') else 0.\n",
    "        hour_x = self.hour_embed(x[:, :, 3])\n",
    "        weekday_x = self.weekday_embed(x[:, :, 2])\n",
    "        day_x = self.day_embed(x[:, :, 1])\n",
    "        month_x = self.month_embed(x[:, :, 0])\n",
    "\n",
    "        return hour_x + weekday_x + day_x + month_x + minute_x\n",
    "\n",
    "\n",
    "class TimeFeatureEmbedding(nn.Module):\n",
    "    def __init__(self, d_model, embed_type='timeF', freq='h'):\n",
    "        super(TimeFeatureEmbedding, self).__init__()\n",
    "\n",
    "        freq_map = {'h': 4, 't': 5, 's': 6,\n",
    "                    'm': 1, 'a': 1, 'w': 2, 'd': 3, 'b': 3}\n",
    "        d_inp = freq_map[freq]\n",
    "        self.embed = nn.Linear(d_inp, d_model, bias=False)\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.embed(x)\n",
    "\n",
    "class PositionalEmbedding(nn.Module):\n",
    "    def __init__(self, d_model, max_len=5000):\n",
    "        super(PositionalEmbedding, self).__init__()\n",
    "        # Compute the positional encodings once in log space.\n",
    "        pe = torch.zeros(max_len, d_model).float()\n",
    "        pe.require_grad = False\n",
    "\n",
    "        position = torch.arange(0, max_len).float().unsqueeze(1)\n",
    "        div_term = (torch.arange(0, d_model, 2).float()\n",
    "                    * -(math.log(10000.0) / d_model)).exp()\n",
    "\n",
    "        pe[:, 0::2] = torch.sin(position * div_term)\n",
    "        pe[:, 1::2] = torch.cos(position * div_term)\n",
    "\n",
    "        pe = pe.unsqueeze(0)\n",
    "        self.register_buffer('pe', pe)\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.pe[:, :x.size(1)]\n",
    "    \n",
    "class DataEmbedding(nn.Module):\n",
    "    def __init__(self, c_in, d_model, embed_type='fixed', freq='h', dropout=0.1):\n",
    "        super(DataEmbedding, self).__init__()\n",
    "\n",
    "        self.value_embedding = TokenEmbedding(c_in=c_in, d_model=d_model)\n",
    "        self.position_embedding = PositionalEmbedding(d_model=d_model)\n",
    "        self.temporal_embedding = TemporalEmbedding(d_model=d_model, embed_type=embed_type,\n",
    "                                                    freq=freq) if embed_type != 'timeF' else TimeFeatureEmbedding(\n",
    "            d_model=d_model, embed_type=embed_type, freq=freq)\n",
    "        self.dropout = nn.Dropout(p=dropout)\n",
    "\n",
    "    def forward(self, x, x_mark):\n",
    "        if x_mark is None:\n",
    "            x = self.value_embedding(x) + self.position_embedding(x)\n",
    "        else:\n",
    "            x = self.value_embedding(\n",
    "                x) + self.temporal_embedding(x_mark) + self.position_embedding(x)\n",
    "        return self.dropout(x)\n",
    "\n",
    "def FFT_for_Period(x, k=2):\n",
    "    # [B, T, C]\n",
    "    xf = torch.fft.rfft(x, dim=1)\n",
    "    # find period by amplitudes\n",
    "    frequency_list = abs(xf).mean(0).mean(-1)\n",
    "    frequency_list[0] = 0\n",
    "    _, top_list = torch.topk(frequency_list, k)\n",
    "    top_list = top_list.detach().cpu().numpy()\n",
    "    period = x.shape[1] // top_list\n",
    "    return period, abs(xf).mean(-1)[:, top_list]\n",
    "\n",
    "\n",
    "class TimesBlock(nn.Module):\n",
    "    def __init__(self, seq_len, pred_len, top_k, d_model, d_ff=32, num_kernels=6):\n",
    "        \"\"\"\n",
    "        seq_len: int, the length of the input sequence\n",
    "        pred_len: int, the length of the prediction sequence\n",
    "        top_k: int denotes how many top frequencies are taken into consideration\n",
    "        d_model is the dimension of embedding\n",
    "        \"\"\"\n",
    "        super(TimesBlock, self).__init__()\n",
    "        self.seq_len = seq_len\n",
    "        self.pred_len = pred_len\n",
    "        self.k = top_k\n",
    "        # parameter-efficient design\n",
    "        self.conv = nn.Sequential(\n",
    "            Inception_Block_V1(d_model, d_ff,\n",
    "                               num_kernels=num_kernels),\n",
    "            nn.GELU(),\n",
    "            Inception_Block_V1(d_ff, d_model,\n",
    "                               num_kernels=num_kernels)\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        B, T, N = x.size()\n",
    "        period_list, period_weight = FFT_for_Period(x, self.k)\n",
    "\n",
    "        res = []\n",
    "        for i in range(self.k):\n",
    "            period = period_list[i]\n",
    "            # padding\n",
    "            if (self.seq_len + self.pred_len) % period != 0:\n",
    "                length = (\n",
    "                                 ((self.seq_len + self.pred_len) // period) + 1) * period\n",
    "                padding = torch.zeros([x.shape[0], (length - (self.seq_len + self.pred_len)), x.shape[2]]).to(x.device)\n",
    "                out = torch.cat([x, padding], dim=1)\n",
    "            else:\n",
    "                length = (self.seq_len + self.pred_len)\n",
    "                out = x\n",
    "            # reshape\n",
    "            out = out.reshape(B, length // period, period,\n",
    "                              N).permute(0, 3, 1, 2).contiguous()\n",
    "            # 2D conv: from 1d Variation to 2d Variation\n",
    "            out = self.conv(out)\n",
    "            # reshape back\n",
    "            out = out.permute(0, 2, 3, 1).reshape(B, -1, N)\n",
    "            res.append(out[:, :(self.seq_len + self.pred_len), :])\n",
    "        res = torch.stack(res, dim=-1)\n",
    "        # adaptive aggregation\n",
    "        period_weight = F.softmax(period_weight, dim=1)\n",
    "        period_weight = period_weight.unsqueeze(\n",
    "            1).unsqueeze(1).repeat(1, T, N, 1)\n",
    "        res = torch.sum(res * period_weight, -1)\n",
    "        # residual connection\n",
    "        res = res + x\n",
    "        return res\n",
    "\n",
    "\n",
    "class Model(nn.Module):\n",
    "    \"\"\"\n",
    "    Paper link: https://openreview.net/pdf?id=ju_Uqw384Oq\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, seq_len, label_len, pred_len, num_encoder_layers=2, top_k=5, d_model=16, enc_in=3, embed=\"timeF\", freq=\"s\", dropout=0, c_out=3):\n",
    "        \"\"\"\n",
    "        enc_in is the encoder input size, the number of features for a piece of data\n",
    "        c_out is the output size, the number of features for a piece of data\n",
    "        \"\"\"\n",
    "        super(Model, self).__init__()\n",
    "        self.seq_len = seq_len\n",
    "        self.label_len = label_len\n",
    "        self.pred_len = pred_len\n",
    "        self.model = nn.ModuleList([TimesBlock(seq_len, pred_len, top_k, d_model, d_ff=32, num_kernels=6)\n",
    "                                    for _ in range(num_encoder_layers)])\n",
    "        self.enc_embedding = DataEmbedding(enc_in, d_model, embed, freq, dropout)\n",
    "        self.layer = num_encoder_layers\n",
    "        self.layer_norm = nn.LayerNorm(d_model)\n",
    "        self.predict_linear = nn.Linear(\n",
    "            self.seq_len, self.pred_len + self.seq_len)\n",
    "        self.projection = nn.Linear(\n",
    "            d_model, c_out, bias=True)\n",
    "        \n",
    "    def forecast(self, x_enc, x_mark_enc):\n",
    "        # Normalization from Non-stationary Transformer\n",
    "        means = x_enc.mean(1, keepdim=True).detach()\n",
    "        x_enc = x_enc - means\n",
    "        stdev = torch.sqrt(\n",
    "            torch.var(x_enc, dim=1, keepdim=True, unbiased=False) + 1e-5)\n",
    "        x_enc /= stdev\n",
    "\n",
    "        # embedding\n",
    "        enc_out = self.enc_embedding(x_enc, x_mark_enc)  # [B,T,C]\n",
    "        enc_out = self.predict_linear(enc_out.permute(0, 2, 1)).permute(\n",
    "            0, 2, 1)  # align temporal dimension\n",
    "        # TimesNet\n",
    "        for i in range(self.layer):\n",
    "            enc_out = self.layer_norm(self.model[i](enc_out))\n",
    "        # porject back\n",
    "        dec_out = self.projection(enc_out)\n",
    "\n",
    "        # De-Normalization from Non-stationary Transformer\n",
    "        dec_out = dec_out * \\\n",
    "                  (stdev[:, 0, :].unsqueeze(1).repeat(\n",
    "                      1, self.pred_len + self.seq_len, 1))\n",
    "        dec_out = dec_out + \\\n",
    "                  (means[:, 0, :].unsqueeze(1).repeat(\n",
    "                      1, self.pred_len + self.seq_len, 1))\n",
    "        return dec_out\n",
    "\n",
    "\n",
    "    def forward(self, x_enc, x_mark_enc):\n",
    "        dec_out = self.forecast(x_enc, x_mark_enc)\n",
    "        return dec_out[:, -self.pred_len:, :]  # [B, L, D]\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# short term forecasting\n",
    "from data_provider.data_factory import data_provider\n",
    "from data_provider.m4 import M4Meta\n",
    "from exp.exp_basic import Exp_Basic\n",
    "from utils.tools import EarlyStopping, adjust_learning_rate, visual\n",
    "from utils.losses import mape_loss, mase_loss, smape_loss\n",
    "from utils.m4_summary import M4Summary\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch import optim\n",
    "import os\n",
    "import time\n",
    "import warnings\n",
    "import numpy as np\n",
    "import pandas\n",
    "\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "\n",
    "class Exp_Short_Term_Forecast(Exp_Basic):\n",
    "    def __init__(self, args):\n",
    "        super(Exp_Short_Term_Forecast, self).__init__(args)\n",
    "\n",
    "    def _build_model(self):\n",
    "        if self.args.data == 'm4':\n",
    "            self.args.pred_len = M4Meta.horizons_map[self.args.seasonal_patterns]  # Up to M4 config\n",
    "            self.args.seq_len = 2 * self.args.pred_len  # input_len = 2*pred_len\n",
    "            self.args.label_len = self.args.pred_len\n",
    "            self.args.frequency_map = M4Meta.frequency_map[self.args.seasonal_patterns]\n",
    "        model = self.model_dict[self.args.model].Model(self.args).float()\n",
    "\n",
    "        if self.args.use_multi_gpu and self.args.use_gpu:\n",
    "            model = nn.DataParallel(model, device_ids=self.args.device_ids)\n",
    "        return model\n",
    "\n",
    "    def _get_data(self, flag):\n",
    "        data_set, data_loader = data_provider(self.args, flag)\n",
    "        return data_set, data_loader\n",
    "\n",
    "    def _select_optimizer(self):\n",
    "        model_optim = optim.Adam(self.model.parameters(), lr=self.args.learning_rate)\n",
    "        return model_optim\n",
    "\n",
    "    def _select_criterion(self, loss_name='MSE'):\n",
    "        if loss_name == 'MSE':\n",
    "            return nn.MSELoss()\n",
    "        elif loss_name == 'MAPE':\n",
    "            return mape_loss()\n",
    "        elif loss_name == 'MASE':\n",
    "            return mase_loss()\n",
    "        elif loss_name == 'SMAPE':\n",
    "            return smape_loss()\n",
    "\n",
    "    def train(self, setting):\n",
    "        train_data, train_loader = self._get_data(flag='train')\n",
    "        vali_data, vali_loader = self._get_data(flag='val')\n",
    "\n",
    "        path = os.path.join(self.args.checkpoints, setting)\n",
    "        if not os.path.exists(path):\n",
    "            os.makedirs(path)\n",
    "\n",
    "        time_now = time.time()\n",
    "\n",
    "        train_steps = len(train_loader)\n",
    "        early_stopping = EarlyStopping(patience=self.args.patience, verbose=True)\n",
    "\n",
    "        model_optim = self._select_optimizer()\n",
    "        criterion = self._select_criterion(self.args.loss)\n",
    "        mse = nn.MSELoss()\n",
    "\n",
    "        for epoch in range(self.args.train_epochs):\n",
    "            iter_count = 0\n",
    "            train_loss = []\n",
    "\n",
    "            self.model.train()\n",
    "            epoch_time = time.time()\n",
    "            for i, (batch_x, batch_y, batch_x_mark, batch_y_mark) in enumerate(train_loader):\n",
    "                iter_count += 1\n",
    "                model_optim.zero_grad()\n",
    "                batch_x = batch_x.float().to(self.device)\n",
    "\n",
    "                batch_y = batch_y.float().to(self.device)\n",
    "                batch_y_mark = batch_y_mark.float().to(self.device)\n",
    "\n",
    "                # decoder input\n",
    "                dec_inp = torch.zeros_like(batch_y[:, -self.args.pred_len:, :]).float()\n",
    "                dec_inp = torch.cat([batch_y[:, :self.args.label_len, :], dec_inp], dim=1).float().to(self.device)\n",
    "\n",
    "                outputs = self.model(batch_x, None, dec_inp, None)\n",
    "\n",
    "                f_dim = -1 if self.args.features == 'MS' else 0\n",
    "                outputs = outputs[:, -self.args.pred_len:, f_dim:]\n",
    "                batch_y = batch_y[:, -self.args.pred_len:, f_dim:].to(self.device)\n",
    "\n",
    "                batch_y_mark = batch_y_mark[:, -self.args.pred_len:, f_dim:].to(self.device)\n",
    "                loss_value = criterion(batch_x, self.args.frequency_map, outputs, batch_y, batch_y_mark)\n",
    "                loss_sharpness = mse((outputs[:, 1:, :] - outputs[:, :-1, :]), (batch_y[:, 1:, :] - batch_y[:, :-1, :]))\n",
    "                loss = loss_value  # + loss_sharpness * 1e-5\n",
    "                train_loss.append(loss.item())\n",
    "\n",
    "                if (i + 1) % 100 == 0:\n",
    "                    print(\"\\titers: {0}, epoch: {1} | loss: {2:.7f}\".format(i + 1, epoch + 1, loss.item()))\n",
    "                    speed = (time.time() - time_now) / iter_count\n",
    "                    left_time = speed * ((self.args.train_epochs - epoch) * train_steps - i)\n",
    "                    print('\\tspeed: {:.4f}s/iter; left time: {:.4f}s'.format(speed, left_time))\n",
    "                    iter_count = 0\n",
    "                    time_now = time.time()\n",
    "\n",
    "                loss.backward()\n",
    "                model_optim.step()\n",
    "\n",
    "            print(\"Epoch: {} cost time: {}\".format(epoch + 1, time.time() - epoch_time))\n",
    "            train_loss = np.average(train_loss)\n",
    "            vali_loss = self.vali(train_loader, vali_loader, criterion)\n",
    "            test_loss = vali_loss\n",
    "            print(\"Epoch: {0}, Steps: {1} | Train Loss: {2:.7f} Vali Loss: {3:.7f} Test Loss: {4:.7f}\".format(\n",
    "                epoch + 1, train_steps, train_loss, vali_loss, test_loss))\n",
    "            early_stopping(vali_loss, self.model, path)\n",
    "            if early_stopping.early_stop:\n",
    "                print(\"Early stopping\")\n",
    "                break\n",
    "\n",
    "            adjust_learning_rate(model_optim, epoch + 1, self.args)\n",
    "\n",
    "        best_model_path = path + '/' + 'checkpoint.pth'\n",
    "        self.model.load_state_dict(torch.load(best_model_path))\n",
    "\n",
    "        return self.model\n",
    "\n",
    "    def vali(self, train_loader, vali_loader, criterion):\n",
    "        x, _ = train_loader.dataset.last_insample_window()\n",
    "        y = vali_loader.dataset.timeseries\n",
    "        x = torch.tensor(x, dtype=torch.float32).to(self.device)\n",
    "        x = x.unsqueeze(-1)\n",
    "\n",
    "        self.model.eval()\n",
    "        with torch.no_grad():\n",
    "            # decoder input\n",
    "            B, _, C = x.shape\n",
    "            dec_inp = torch.zeros((B, self.args.pred_len, C)).float().to(self.device)\n",
    "            dec_inp = torch.cat([x[:, -self.args.label_len:, :], dec_inp], dim=1).float()\n",
    "            # encoder - decoder\n",
    "            outputs = torch.zeros((B, self.args.pred_len, C)).float()  # .to(self.device)\n",
    "            id_list = np.arange(0, B, 500)  # validation set size\n",
    "            id_list = np.append(id_list, B)\n",
    "            for i in range(len(id_list) - 1):\n",
    "                outputs[id_list[i]:id_list[i + 1], :, :] = self.model(x[id_list[i]:id_list[i + 1]], None,\n",
    "                                                                      dec_inp[id_list[i]:id_list[i + 1]],\n",
    "                                                                      None).detach().cpu()\n",
    "            f_dim = -1 if self.args.features == 'MS' else 0\n",
    "            outputs = outputs[:, -self.args.pred_len:, f_dim:]\n",
    "            pred = outputs\n",
    "            true = torch.from_numpy(np.array(y))\n",
    "            batch_y_mark = torch.ones(true.shape)\n",
    "\n",
    "            loss = criterion(x.detach().cpu()[:, :, 0], self.args.frequency_map, pred[:, :, 0], true, batch_y_mark)\n",
    "\n",
    "        self.model.train()\n",
    "        return loss\n",
    "\n",
    "    def test(self, setting, test=0):\n",
    "        _, train_loader = self._get_data(flag='train')\n",
    "        _, test_loader = self._get_data(flag='test')\n",
    "        x, _ = train_loader.dataset.last_insample_window()\n",
    "        y = test_loader.dataset.timeseries\n",
    "        x = torch.tensor(x, dtype=torch.float32).to(self.device)\n",
    "        x = x.unsqueeze(-1)\n",
    "\n",
    "        if test:\n",
    "            print('loading model')\n",
    "            self.model.load_state_dict(torch.load(os.path.join('./checkpoints/' + setting, 'checkpoint.pth')))\n",
    "\n",
    "        folder_path = './test_results/' + setting + '/'\n",
    "        if not os.path.exists(folder_path):\n",
    "            os.makedirs(folder_path)\n",
    "\n",
    "        self.model.eval()\n",
    "        with torch.no_grad():\n",
    "            B, _, C = x.shape\n",
    "            dec_inp = torch.zeros((B, self.args.pred_len, C)).float().to(self.device)\n",
    "            dec_inp = torch.cat([x[:, -self.args.label_len:, :], dec_inp], dim=1).float()\n",
    "            # encoder - decoder\n",
    "            outputs = torch.zeros((B, self.args.pred_len, C)).float().to(self.device)\n",
    "            id_list = np.arange(0, B, 1)\n",
    "            id_list = np.append(id_list, B)\n",
    "            for i in range(len(id_list) - 1):\n",
    "                outputs[id_list[i]:id_list[i + 1], :, :] = self.model(x[id_list[i]:id_list[i + 1]], None,\n",
    "                                                                      dec_inp[id_list[i]:id_list[i + 1]], None)\n",
    "\n",
    "                if id_list[i] % 1000 == 0:\n",
    "                    print(id_list[i])\n",
    "\n",
    "            f_dim = -1 if self.args.features == 'MS' else 0\n",
    "            outputs = outputs[:, -self.args.pred_len:, f_dim:]\n",
    "            outputs = outputs.detach().cpu().numpy()\n",
    "\n",
    "            preds = outputs\n",
    "            trues = y\n",
    "            x = x.detach().cpu().numpy()\n",
    "\n",
    "            for i in range(0, preds.shape[0], preds.shape[0] // 10):\n",
    "                gt = np.concatenate((x[i, :, 0], trues[i]), axis=0)\n",
    "                pd = np.concatenate((x[i, :, 0], preds[i, :, 0]), axis=0)\n",
    "                visual(gt, pd, os.path.join(folder_path, str(i) + '.pdf'))\n",
    "\n",
    "        print('test shape:', preds.shape)\n",
    "\n",
    "        # result save\n",
    "        folder_path = './m4_results/' + self.args.model + '/'\n",
    "        if not os.path.exists(folder_path):\n",
    "            os.makedirs(folder_path)\n",
    "\n",
    "        forecasts_df = pandas.DataFrame(preds[:, :, 0], columns=[f'V{i + 1}' for i in range(self.args.pred_len)])\n",
    "        forecasts_df.index = test_loader.dataset.ids[:preds.shape[0]]\n",
    "        forecasts_df.index.name = 'id'\n",
    "        forecasts_df.set_index(forecasts_df.columns[0], inplace=True)\n",
    "        forecasts_df.to_csv(folder_path + self.args.seasonal_patterns + '_forecast.csv')\n",
    "\n",
    "        print(self.args.model)\n",
    "        file_path = './m4_results/' + self.args.model + '/'\n",
    "        if 'Weekly_forecast.csv' in os.listdir(file_path) \\\n",
    "                and 'Monthly_forecast.csv' in os.listdir(file_path) \\\n",
    "                and 'Yearly_forecast.csv' in os.listdir(file_path) \\\n",
    "                and 'Daily_forecast.csv' in os.listdir(file_path) \\\n",
    "                and 'Hourly_forecast.csv' in os.listdir(file_path) \\\n",
    "                and 'Quarterly_forecast.csv' in os.listdir(file_path):\n",
    "            m4_summary = M4Summary(file_path, self.args.root_path)\n",
    "            # m4_forecast.set_index(m4_winner_forecast.columns[0], inplace=True)\n",
    "            smape_results, owa_results, mape, mase = m4_summary.evaluate()\n",
    "            print('smape:', smape_results)\n",
    "            print('mape:', mape)\n",
    "            print('mase:', mase)\n",
    "            print('owa:', owa_results)\n",
    "        else:\n",
    "            print('After all 6 tasks are finished, you can calculate the averaged index')\n",
    "        return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "leo = pandas.read_csv('dataset/BTD.txt')\n",
    "\n",
    "df = pd.DataFrame(leo)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting jinja2\n",
      "  Using cached jinja2-3.1.4-py3-none-any.whl.metadata (2.6 kB)\n",
      "Collecting MarkupSafe>=2.0 (from jinja2)\n",
      "  Downloading MarkupSafe-2.1.5-cp38-cp38-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (3.0 kB)\n",
      "Using cached jinja2-3.1.4-py3-none-any.whl (133 kB)\n",
      "Downloading MarkupSafe-2.1.5-cp38-cp38-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (26 kB)\n",
      "Installing collected packages: MarkupSafe, jinja2\n",
      "Successfully installed MarkupSafe-2.1.5 jinja2-3.1.4\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install jinja2\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style type=\"text/css\">\n",
       "#T_92649_row0_col0, #T_92649_row1_col1, #T_92649_row2_col2, #T_92649_row3_col3, #T_92649_row4_col4 {\n",
       "  background-color: #b40426;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_92649_row0_col1, #T_92649_row4_col1 {\n",
       "  background-color: #3e51c5;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_92649_row0_col2 {\n",
       "  background-color: #e1dad6;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_92649_row0_col3 {\n",
       "  background-color: #4b64d5;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_92649_row0_col4, #T_92649_row2_col1, #T_92649_row4_col0, #T_92649_row4_col2, #T_92649_row4_col3 {\n",
       "  background-color: #3b4cc0;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_92649_row1_col0, #T_92649_row1_col4 {\n",
       "  background-color: #82a6fb;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_92649_row1_col2 {\n",
       "  background-color: #455cce;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_92649_row1_col3 {\n",
       "  background-color: #4f69d9;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_92649_row2_col0 {\n",
       "  background-color: #f2cab5;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_92649_row2_col3 {\n",
       "  background-color: #4a63d3;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_92649_row2_col4 {\n",
       "  background-color: #7597f6;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_92649_row3_col0 {\n",
       "  background-color: #7ea1fa;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_92649_row3_col1 {\n",
       "  background-color: #3c4ec2;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_92649_row3_col2 {\n",
       "  background-color: #4257c9;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_92649_row3_col4 {\n",
       "  background-color: #6e90f2;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "</style>\n",
       "<table id=\"T_92649\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th class=\"blank level0\" >&nbsp;</th>\n",
       "      <th id=\"T_92649_level0_col0\" class=\"col_heading level0 col0\" >bone_id</th>\n",
       "      <th id=\"T_92649_level0_col1\" class=\"col_heading level0 col1\" >frame_id</th>\n",
       "      <th id=\"T_92649_level0_col2\" class=\"col_heading level0 col2\" >x</th>\n",
       "      <th id=\"T_92649_level0_col3\" class=\"col_heading level0 col3\" >y</th>\n",
       "      <th id=\"T_92649_level0_col4\" class=\"col_heading level0 col4\" >z</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th id=\"T_92649_level0_row0\" class=\"row_heading level0 row0\" >bone_id</th>\n",
       "      <td id=\"T_92649_row0_col0\" class=\"data row0 col0\" >1.000000</td>\n",
       "      <td id=\"T_92649_row0_col1\" class=\"data row0 col1\" >-0.000000</td>\n",
       "      <td id=\"T_92649_row0_col2\" class=\"data row0 col2\" >0.492229</td>\n",
       "      <td id=\"T_92649_row0_col3\" class=\"data row0 col3\" >-0.019477</td>\n",
       "      <td id=\"T_92649_row0_col4\" class=\"data row0 col4\" >-0.286231</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_92649_level0_row1\" class=\"row_heading level0 row1\" >frame_id</th>\n",
       "      <td id=\"T_92649_row1_col0\" class=\"data row1 col0\" >-0.000000</td>\n",
       "      <td id=\"T_92649_row1_col1\" class=\"data row1 col1\" >1.000000</td>\n",
       "      <td id=\"T_92649_row1_col2\" class=\"data row1 col2\" >-0.012515</td>\n",
       "      <td id=\"T_92649_row1_col3\" class=\"data row1 col3\" >-0.007059</td>\n",
       "      <td id=\"T_92649_row1_col4\" class=\"data row1 col4\" >-0.000220</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_92649_level0_row2\" class=\"row_heading level0 row2\" >x</th>\n",
       "      <td id=\"T_92649_row2_col0\" class=\"data row2 col0\" >0.492229</td>\n",
       "      <td id=\"T_92649_row2_col1\" class=\"data row2 col1\" >-0.012515</td>\n",
       "      <td id=\"T_92649_row2_col2\" class=\"data row2 col2\" >1.000000</td>\n",
       "      <td id=\"T_92649_row2_col3\" class=\"data row2 col3\" >-0.022136</td>\n",
       "      <td id=\"T_92649_row2_col4\" class=\"data row2 col4\" >-0.050141</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_92649_level0_row3\" class=\"row_heading level0 row3\" >y</th>\n",
       "      <td id=\"T_92649_row3_col0\" class=\"data row3 col0\" >-0.019477</td>\n",
       "      <td id=\"T_92649_row3_col1\" class=\"data row3 col1\" >-0.007059</td>\n",
       "      <td id=\"T_92649_row3_col2\" class=\"data row3 col2\" >-0.022136</td>\n",
       "      <td id=\"T_92649_row3_col3\" class=\"data row3 col3\" >1.000000</td>\n",
       "      <td id=\"T_92649_row3_col4\" class=\"data row3 col4\" >-0.079474</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_92649_level0_row4\" class=\"row_heading level0 row4\" >z</th>\n",
       "      <td id=\"T_92649_row4_col0\" class=\"data row4 col0\" >-0.286231</td>\n",
       "      <td id=\"T_92649_row4_col1\" class=\"data row4 col1\" >-0.000220</td>\n",
       "      <td id=\"T_92649_row4_col2\" class=\"data row4 col2\" >-0.050141</td>\n",
       "      <td id=\"T_92649_row4_col3\" class=\"data row4 col3\" >-0.079474</td>\n",
       "      <td id=\"T_92649_row4_col4\" class=\"data row4 col4\" >1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n"
      ],
      "text/plain": [
       "<pandas.io.formats.style.Styler at 0x7fc7d596ceb0>"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "corr = leo.corr()\n",
    "corr.style.background_gradient(cmap='coolwarm')\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "timesnet-env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
